{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2455b14",
   "metadata": {},
   "source": [
    "# HW3\n",
    "\n",
    "## Text Processing\n",
    "\n",
    "### Q1\n",
    "\n",
    "1. Modify the code I wrote in lecture 8 with what you have learnt in lecture 9 and correctly tokenize the text both on the word and sentence level, and by removing the stopwords. Rewrite the `getSummary` function and all the other functions that it depends by maing these corrections.\n",
    "\n",
    "2. Rewrite the code I wrote for `getKeywords` function making the same corrections.\n",
    "\n",
    "3. Test your code from parts 1 and 2 on random articles from the Guardian.\n",
    "\n",
    "4. Rewrite the `getSubjectGuardian` function for another newspaper in English, and test your code from part 1 and 2 on random articles from this new newspaper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a941a3b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import nltk\n",
    "import regex as re\n",
    "import spacy\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from bs4 import BeautifulSoup\n",
    "from xmltodict import parse\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "399cb2d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "with requests.get('https://www.theguardian.com/technology/rss') as link:\n",
    "    raw = parse(link.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3b5a5d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "nal = raw['rss']['channel']['item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "319e311b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getText(url):\n",
    "    with requests.get(url) as link:\n",
    "        raw = BeautifulSoup(link.content,'html.parser')\n",
    "    return ' '.join([x.text for x in raw.find_all('p')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5aee2c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "text=getText(nal[0]['link'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a3eddd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "omats = {'sentences': sent_tokenize(text),\n",
    "         'words': word_tokenize(text)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d0cb7805",
   "metadata": {},
   "outputs": [],
   "source": [
    "omats.update({'sentences': [re.sub(r'[^\\p{Letter}\\s]','',sentence.lower()) for sentence in omats['sentences']],\n",
    "              'words': [re.sub(r'[^\\p{Letter}]','',word.lower()) for word in omats['words']]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2de4da63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'a',\n",
       " 'about',\n",
       " 'above',\n",
       " 'after',\n",
       " 'again',\n",
       " 'against',\n",
       " 'ain',\n",
       " 'all',\n",
       " 'am',\n",
       " 'an',\n",
       " 'and',\n",
       " 'any',\n",
       " 'are',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'as',\n",
       " 'at',\n",
       " 'be',\n",
       " 'because',\n",
       " 'been',\n",
       " 'before',\n",
       " 'being',\n",
       " 'below',\n",
       " 'between',\n",
       " 'both',\n",
       " 'but',\n",
       " 'by',\n",
       " 'can',\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'd',\n",
       " 'did',\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'do',\n",
       " 'does',\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'doing',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'down',\n",
       " 'during',\n",
       " 'each',\n",
       " 'few',\n",
       " 'for',\n",
       " 'from',\n",
       " 'further',\n",
       " 'had',\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'has',\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'have',\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'having',\n",
       " 'he',\n",
       " 'her',\n",
       " 'here',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'him',\n",
       " 'himself',\n",
       " 'his',\n",
       " 'how',\n",
       " 'i',\n",
       " 'if',\n",
       " 'in',\n",
       " 'into',\n",
       " 'is',\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'just',\n",
       " 'll',\n",
       " 'm',\n",
       " 'ma',\n",
       " 'me',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'more',\n",
       " 'most',\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'my',\n",
       " 'myself',\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'now',\n",
       " 'o',\n",
       " 'of',\n",
       " 'off',\n",
       " 'on',\n",
       " 'once',\n",
       " 'only',\n",
       " 'or',\n",
       " 'other',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'out',\n",
       " 'over',\n",
       " 'own',\n",
       " 're',\n",
       " 's',\n",
       " 'same',\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'so',\n",
       " 'some',\n",
       " 'such',\n",
       " 't',\n",
       " 'than',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'the',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'them',\n",
       " 'themselves',\n",
       " 'then',\n",
       " 'there',\n",
       " 'these',\n",
       " 'they',\n",
       " 'this',\n",
       " 'those',\n",
       " 'through',\n",
       " 'to',\n",
       " 'too',\n",
       " 'under',\n",
       " 'until',\n",
       " 'up',\n",
       " 've',\n",
       " 'very',\n",
       " 'was',\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'we',\n",
       " 'were',\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'what',\n",
       " 'when',\n",
       " 'where',\n",
       " 'which',\n",
       " 'while',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'why',\n",
       " 'will',\n",
       " 'with',\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\",\n",
       " 'y',\n",
       " 'you',\n",
       " \"you'd\",\n",
       " \"you'll\",\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swEN = set(stopwords.words('english'))\n",
    "swEN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd1daa22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['world',\n",
       " '',\n",
       " 'richest',\n",
       " 'person',\n",
       " 'aims',\n",
       " 'reassure',\n",
       " 'followers',\n",
       " '',\n",
       " 'saying',\n",
       " 'seek',\n",
       " 'politicise',\n",
       " 'social',\n",
       " 'media',\n",
       " 'network',\n",
       " 'elon',\n",
       " 'musk',\n",
       " 'said',\n",
       " 'twitter',\n",
       " 'must',\n",
       " '',\n",
       " 'politically',\n",
       " 'neutral',\n",
       " '',\n",
       " 'comment',\n",
       " 'posted',\n",
       " 'last',\n",
       " 'night',\n",
       " 'wave',\n",
       " 'account',\n",
       " 'deletions',\n",
       " 'leftleaning',\n",
       " 'users',\n",
       " 'social',\n",
       " 'media',\n",
       " 'network',\n",
       " '',\n",
       " 'days',\n",
       " 'since',\n",
       " 'musk',\n",
       " '',\n",
       " '',\n",
       " 'bn',\n",
       " '',\n",
       " 'bn',\n",
       " '',\n",
       " 'acquisition',\n",
       " 'offer',\n",
       " 'accepted',\n",
       " 'twitter',\n",
       " '',\n",
       " 'board',\n",
       " '',\n",
       " 'hundreds',\n",
       " 'thousands',\n",
       " 'users',\n",
       " 'closed',\n",
       " 'accounts',\n",
       " 'site',\n",
       " '',\n",
       " 'company',\n",
       " 'confirmed',\n",
       " '',\n",
       " 'leading',\n",
       " 'dip',\n",
       " 'follower',\n",
       " 'numbers',\n",
       " 'leftleaning',\n",
       " 'politicians',\n",
       " 'celebrities',\n",
       " 'barack',\n",
       " 'michelle',\n",
       " 'obama',\n",
       " '',\n",
       " 'taylor',\n",
       " 'swift',\n",
       " 'jeremy',\n",
       " 'corbyn',\n",
       " '',\n",
       " 'meanwhile',\n",
       " '',\n",
       " 'rightwing',\n",
       " 'influencers',\n",
       " 'farright',\n",
       " 'congresswoman',\n",
       " 'marjorie',\n",
       " 'taylor',\n",
       " 'greene',\n",
       " '',\n",
       " 'boris',\n",
       " 'johnson',\n",
       " 'ted',\n",
       " 'cruz',\n",
       " 'large',\n",
       " 'gains',\n",
       " 'new',\n",
       " 'users',\n",
       " 'sign',\n",
       " 'service',\n",
       " '',\n",
       " 'latest',\n",
       " 'series',\n",
       " 'tweets',\n",
       " 'platform',\n",
       " 'musk',\n",
       " 'hopes',\n",
       " 'take',\n",
       " 'private',\n",
       " 'ownership',\n",
       " '',\n",
       " 'world',\n",
       " '',\n",
       " 'wealthiest',\n",
       " 'person',\n",
       " 'suggested',\n",
       " 'would',\n",
       " 'seek',\n",
       " 'politicise',\n",
       " 'twitter',\n",
       " '',\n",
       " '',\n",
       " 'twitter',\n",
       " 'deserve',\n",
       " 'public',\n",
       " 'trust',\n",
       " 'must',\n",
       " 'politically',\n",
       " 'neutral',\n",
       " '',\n",
       " 'effectively',\n",
       " 'means',\n",
       " 'upsetting',\n",
       " 'far',\n",
       " 'right',\n",
       " 'far',\n",
       " 'left',\n",
       " 'equally',\n",
       " '',\n",
       " '',\n",
       " 'tweeted',\n",
       " 'yesterday',\n",
       " 'evening',\n",
       " '',\n",
       " 'earlier',\n",
       " 'comments',\n",
       " '',\n",
       " 'musk',\n",
       " 'outspoken',\n",
       " 'desire',\n",
       " 'promote',\n",
       " 'free',\n",
       " 'speech',\n",
       " 'twitter',\n",
       " '',\n",
       " 'saying',\n",
       " '',\n",
       " 'censorship',\n",
       " 'goes',\n",
       " 'far',\n",
       " 'beyond',\n",
       " 'law',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'people',\n",
       " 'want',\n",
       " 'less',\n",
       " 'free',\n",
       " 'speech',\n",
       " '',\n",
       " 'ask',\n",
       " 'government',\n",
       " 'pass',\n",
       " 'laws',\n",
       " 'effect',\n",
       " '',\n",
       " '',\n",
       " 'musk',\n",
       " 'added',\n",
       " '',\n",
       " '',\n",
       " 'therefore',\n",
       " '',\n",
       " 'going',\n",
       " 'beyond',\n",
       " 'law',\n",
       " 'contrary',\n",
       " 'people',\n",
       " '',\n",
       " 'statements',\n",
       " 'interpreted',\n",
       " 'criticism',\n",
       " 'twitter',\n",
       " '',\n",
       " 'existing',\n",
       " 'moderation',\n",
       " 'policies',\n",
       " '',\n",
       " 'particularly',\n",
       " 'affected',\n",
       " 'us',\n",
       " 'right',\n",
       " '',\n",
       " 'former',\n",
       " 'president',\n",
       " 'donald',\n",
       " 'trump',\n",
       " 'banned',\n",
       " 'social',\n",
       " 'network',\n",
       " '',\n",
       " 'role',\n",
       " 'encouraging',\n",
       " 'storming',\n",
       " 'us',\n",
       " 'capitol',\n",
       " '',\n",
       " 'greene',\n",
       " 'personal',\n",
       " 'account',\n",
       " 'permanently',\n",
       " 'suspended',\n",
       " 'breaking',\n",
       " 'platform',\n",
       " '',\n",
       " 'fivestrike',\n",
       " 'rule',\n",
       " '',\n",
       " 'musk',\n",
       " 'argued',\n",
       " 'changes',\n",
       " 'would',\n",
       " 'affect',\n",
       " 'users',\n",
       " '',\n",
       " '',\n",
       " 'attacks',\n",
       " 'coming',\n",
       " 'thick',\n",
       " 'fast',\n",
       " '',\n",
       " 'primarily',\n",
       " 'left',\n",
       " '',\n",
       " 'surprise',\n",
       " '',\n",
       " '',\n",
       " 'said',\n",
       " '',\n",
       " 'reply',\n",
       " 'rightwing',\n",
       " 'media',\n",
       " 'personality',\n",
       " 'ben',\n",
       " 'shapiro',\n",
       " '',\n",
       " '',\n",
       " 'however',\n",
       " '',\n",
       " 'clear',\n",
       " 'right',\n",
       " 'probably',\n",
       " 'little',\n",
       " 'unhappy',\n",
       " '',\n",
       " 'goal',\n",
       " 'maximise',\n",
       " 'area',\n",
       " 'curve',\n",
       " 'total',\n",
       " 'human',\n",
       " 'happiness',\n",
       " '',\n",
       " 'means',\n",
       " '',\n",
       " '',\n",
       " 'people',\n",
       " 'middle',\n",
       " '',\n",
       " 'response',\n",
       " 'acquisition',\n",
       " 'equally',\n",
       " 'distributed',\n",
       " '',\n",
       " 'however',\n",
       " '',\n",
       " 'katy',\n",
       " 'perry',\n",
       " '',\n",
       " 'pop',\n",
       " 'star',\n",
       " 'site',\n",
       " '',\n",
       " 'third',\n",
       " 'biggest',\n",
       " 'user',\n",
       " '',\n",
       " 'lost',\n",
       " '',\n",
       " 'followers',\n",
       " 'days',\n",
       " '',\n",
       " 'obama',\n",
       " '',\n",
       " 'whose',\n",
       " '',\n",
       " 'million',\n",
       " 'followers',\n",
       " 'make',\n",
       " 'former',\n",
       " 'us',\n",
       " 'president',\n",
       " '',\n",
       " 'account',\n",
       " 'popular',\n",
       " 'site',\n",
       " '',\n",
       " 'lost',\n",
       " '',\n",
       " 'tuesday',\n",
       " 'alone',\n",
       " '',\n",
       " 'followers',\n",
       " 'former',\n",
       " 'first',\n",
       " 'lady',\n",
       " 'michelle',\n",
       " 'obama',\n",
       " 'nearly',\n",
       " '',\n",
       " '',\n",
       " 'cruz',\n",
       " '',\n",
       " 'junior',\n",
       " 'senator',\n",
       " 'texas',\n",
       " '',\n",
       " 'added',\n",
       " '',\n",
       " 'followers',\n",
       " '',\n",
       " 'greene',\n",
       " 'gained',\n",
       " '',\n",
       " 'followers',\n",
       " 'last',\n",
       " 'week',\n",
       " '',\n",
       " 'tenfold',\n",
       " 'increase',\n",
       " 'normal',\n",
       " 'rate',\n",
       " '',\n",
       " 'followers',\n",
       " 'johnson',\n",
       " 'nearly',\n",
       " '',\n",
       " '',\n",
       " 'twitter',\n",
       " 'account',\n",
       " 'former',\n",
       " 'labour',\n",
       " 'leader',\n",
       " 'jeremy',\n",
       " 'corbyn',\n",
       " 'lost',\n",
       " '',\n",
       " 'followers',\n",
       " '',\n",
       " 'speculated',\n",
       " 'changes',\n",
       " 'result',\n",
       " 'action',\n",
       " 'twitter',\n",
       " '',\n",
       " 'cleaning',\n",
       " 'house',\n",
       " '',\n",
       " 'preparation',\n",
       " 'acquisition',\n",
       " '',\n",
       " 'social',\n",
       " 'network',\n",
       " 'said',\n",
       " 'result',\n",
       " '',\n",
       " 'organic',\n",
       " '',\n",
       " 'activity',\n",
       " '',\n",
       " '',\n",
       " 'continue',\n",
       " 'take',\n",
       " 'action',\n",
       " 'accounts',\n",
       " 'violate',\n",
       " 'spam',\n",
       " 'policy',\n",
       " 'affect',\n",
       " 'follower',\n",
       " 'counts',\n",
       " '',\n",
       " 'fluctuations',\n",
       " 'appear',\n",
       " 'largely',\n",
       " 'result',\n",
       " 'increase',\n",
       " 'new',\n",
       " 'account',\n",
       " 'creation',\n",
       " 'deactivation',\n",
       " '',\n",
       " '',\n",
       " 'spokesperson',\n",
       " 'said',\n",
       " '',\n",
       " 'much',\n",
       " 'musk',\n",
       " '',\n",
       " 'criticism',\n",
       " 'twitter',\n",
       " '',\n",
       " 'moderation',\n",
       " 'practices',\n",
       " 'focused',\n",
       " 'single',\n",
       " 'employee',\n",
       " '',\n",
       " 'vijaya',\n",
       " 'gadde',\n",
       " '',\n",
       " 'company',\n",
       " '',\n",
       " 'chief',\n",
       " 'legal',\n",
       " 'officer',\n",
       " '',\n",
       " 'tweets',\n",
       " 'sparked',\n",
       " 'tens',\n",
       " 'thousands',\n",
       " 'abusive',\n",
       " 'messages',\n",
       " 'targeted',\n",
       " 'executive',\n",
       " '',\n",
       " 'public',\n",
       " 'rebuke',\n",
       " 'former',\n",
       " 'twitter',\n",
       " 'chief',\n",
       " 'executive',\n",
       " '',\n",
       " 'dick',\n",
       " 'costolo',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'going',\n",
       " '',\n",
       " '',\n",
       " 'costolo',\n",
       " 'tweeted',\n",
       " 'musk',\n",
       " '',\n",
       " '',\n",
       " '',\n",
       " 'making',\n",
       " 'executive',\n",
       " 'company',\n",
       " 'bought',\n",
       " 'target',\n",
       " 'harassment',\n",
       " 'threats',\n",
       " '',\n",
       " '',\n",
       " 'bullying',\n",
       " 'leadership',\n",
       " '',\n",
       " '',\n",
       " 'added',\n",
       " 'later',\n",
       " '',\n",
       " 'musk',\n",
       " 'replied',\n",
       " '',\n",
       " '',\n",
       " 'talking',\n",
       " '',\n",
       " '',\n",
       " 'saying',\n",
       " 'twitter',\n",
       " 'needs',\n",
       " 'politically',\n",
       " 'neutral',\n",
       " '',\n",
       " 'social',\n",
       " 'media',\n",
       " 'platform',\n",
       " 'admitted',\n",
       " 'first',\n",
       " 'quarter',\n",
       " 'results',\n",
       " 'thursday',\n",
       " 'overstated',\n",
       " 'user',\n",
       " 'numbers',\n",
       " 'nearly',\n",
       " '',\n",
       " 'million',\n",
       " 'first',\n",
       " 'quarter',\n",
       " '',\n",
       " 'last',\n",
       " 'quarter',\n",
       " '',\n",
       " '',\n",
       " 'twitter',\n",
       " 'said',\n",
       " 'miscount',\n",
       " 'monetisable',\n",
       " 'daily',\n",
       " 'active',\n",
       " 'users',\n",
       " 'error',\n",
       " 'feature',\n",
       " 'allowed',\n",
       " 'people',\n",
       " 'link',\n",
       " 'multiple',\n",
       " 'separate',\n",
       " 'accounts',\n",
       " 'together',\n",
       " 'conveniently',\n",
       " 'switch',\n",
       " '',\n",
       " 'company',\n",
       " '',\n",
       " 'million',\n",
       " 'daily',\n",
       " 'users',\n",
       " 'first',\n",
       " 'quarter',\n",
       " 'year',\n",
       " '',\n",
       " '',\n",
       " 'million',\n",
       " 'previous',\n",
       " 'three',\n",
       " 'months',\n",
       " '',\n",
       " 'rise',\n",
       " 'slightly',\n",
       " 'higher',\n",
       " 'analysts',\n",
       " 'expected',\n",
       " '',\n",
       " 'may',\n",
       " 'one',\n",
       " 'final',\n",
       " 'earnings',\n",
       " 'reports',\n",
       " 'public',\n",
       " 'company',\n",
       " '',\n",
       " 'twitter',\n",
       " 'also',\n",
       " 'announced',\n",
       " 'revenue',\n",
       " 'rose',\n",
       " '',\n",
       " 'bn',\n",
       " 'first',\n",
       " 'quarter',\n",
       " '',\n",
       " '',\n",
       " 'bn',\n",
       " 'year',\n",
       " 'earlier',\n",
       " 'slightly',\n",
       " 'lower',\n",
       " 'forecasted',\n",
       " '',\n",
       " 'thursday',\n",
       " '',\n",
       " 'federal',\n",
       " 'trade',\n",
       " 'commission',\n",
       " '',\n",
       " 'looking',\n",
       " 'whether',\n",
       " 'musk',\n",
       " 'complied',\n",
       " 'antitrust',\n",
       " 'reporting',\n",
       " 'requirement',\n",
       " 'bought',\n",
       " 'stake',\n",
       " 'twitter',\n",
       " 'earlier',\n",
       " 'month',\n",
       " '',\n",
       " 'reuters',\n",
       " 'reported',\n",
       " '',\n",
       " 'citing',\n",
       " 'information',\n",
       " '',\n",
       " 'inquiry',\n",
       " 'attempting',\n",
       " 'determine',\n",
       " 'musk',\n",
       " 'bought',\n",
       " 'stake',\n",
       " 'influence',\n",
       " 'twitter',\n",
       " '',\n",
       " 'management',\n",
       " 'looked',\n",
       " 'passive',\n",
       " 'shareholder',\n",
       " '']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reduced = [word for word in omats['words'] if word not in swEN]\n",
    "reduced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fbe36f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def processText(text):\n",
    "    sentences = re.split(r'[.?!]',text)\n",
    "    return [re.sub(r'[^\\w\\s]','',x.lower()) for x in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d6b6affe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getMatrix(sentences):\n",
    "    vectorizer = CountVectorizer()\n",
    "    return vectorizer.fit_transform(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c3883d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSummary(text,k):\n",
    "    sentences = processText(text)\n",
    "    matrix = getMatrix(sentences)\n",
    "    projection = PCA(n_components=1)\n",
    "    weights = projection.fit_transform(matrix.toarray())\n",
    "    res = list(zip(weights.transpose()[0],range(112),sentences))\n",
    "    tmp = sorted(res,key=lambda x: x[0],reverse=True)[:k]\n",
    "    return sorted(tmp, key=lambda x: x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c8d3d787",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(4.516465690943847,\n",
       "  10,\n",
       "  ' the former president donald trump was banned from the social network in 2021 for his role in encouraging the storming of the us capitol while greene had her personal account permanently suspended after breaking the platforms fivestrike rule'),\n",
       " (4.474975719233619,\n",
       "  16,\n",
       "  ' katy perry the pop star who is the sites third biggest user lost 7000 followers in a few days while obama whose 132 million followers make the former us presidents account the most popular on the site lost 5000 on tuesday alone'),\n",
       " (1.9216698829643972,\n",
       "  18,\n",
       "  ' cruz the junior senator for texas added more than 60000 followers while greene gained more than 100000 followers in the last week a tenfold increase in the normal rate'),\n",
       " (3.893372354309854,\n",
       "  20,\n",
       "  ' some speculated that the changes were the result of action from twitter cleaning house in preparation for the acquisition but the social network said they were the result of organic activity'),\n",
       " (2.5005054706430534,\n",
       "  29,\n",
       "  ' the social media platform admitted in its first quarter results on thursday that it had overstated its user numbers by nearly 2 million between the first quarter of 2019 and the last quarter of 2021'),\n",
       " (1.5647813940563637,\n",
       "  31,\n",
       "  '  the company had 229 million daily users in the first quarter of the year up from 214')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getSummary(text,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34d91ce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eab7a63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab569a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0957b90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c148a291",
   "metadata": {},
   "source": [
    "### Q2\n",
    "\n",
    "Write a function that returns all named entities (proper names, country names, corporation names only) from a URL. Function should take the URL as the input and must return the list of named entities from that URL. Test your code on random articles from the Guardian. Don't use the NLTK's NER that I demonstrated during the lecture. Use the SpaCY's NER function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39ef7e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "NER = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7cd27509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def function(url):\n",
    "    with requests.get(url) as link:\n",
    "        raw = BeautifulSoup(link.content,'html.parser')\n",
    "    txt=' '.join([x.text for x in raw.find_all('p')])\n",
    "    res = NER(txt)\n",
    "    person=[]\n",
    "    country=[]\n",
    "    corp=[]\n",
    "    for word in res.ents:\n",
    "        if word.label_== 'PERSON':\n",
    "            person.append(word.text)\n",
    "        if word.label_== 'GPE':\n",
    "            country.append(word.text)\n",
    "        if word.label_== 'ORG':\n",
    "            corp.append(word.text)\n",
    "    print('proper person names' ,person)     \n",
    "    print('country',country)\n",
    "    print('corparation',corp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "168b72b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "proper person names ['Musk', 'Barack', 'Michelle Obama', 'Taylor Swift', 'Jeremy Corbyn', 'Marjorie Taylor Greene', 'Boris Johnson', 'Ted Cruz', 'Musk', 'Musk', 'Musk', 'Donald Trump', 'Musk', 'Ben Shapiro', 'Katy Perry', 'Michelle Obama', 'Cruz', 'Johnson', 'Jeremy Corbyn', 'Musk', 'Dick Costolo', 'Musk', 'Musk', 'Musk', 'Musk']\n",
      "country ['US', 'US', '~80', 'US', 'Texas']\n",
      "corparation ['Twitter', 'Twitter', 'Twitter', 'Greene', 'Greene', 'Twitter', 'Labour', 'Twitter', 'Vijaya Gadde', 'Twitter', 'Twitter', 'the Federal Trade Commission', 'Reuters', 'Information', 'Twitter']\n"
     ]
    }
   ],
   "source": [
    "function(nal[0]['link'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82d80aaa",
   "metadata": {},
   "source": [
    "### Q3\n",
    "\n",
    "1. Write a function that returns the most positive and the most negative sentences from a text. The function must take the text as the input and must return a 2-tuple: the first element as the most positive and the second as the most negative sentence with their polarity scores.\n",
    "\n",
    "2. Test your function on random articles from the Guardian."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c0c48580",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e45b3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def finds(text):\n",
    "    sentences = sent_tokenize(text)\n",
    "    a=[]\n",
    "    for x in sentences:\n",
    "        a.append(analyzer.polarity_scores(x))\n",
    "    pozitif=[]\n",
    "    negatif=[]\n",
    "    for i in a:\n",
    "        pozitif.append(i['pos'])\n",
    "        negatif.append(i['neg'])\n",
    "    indexp=pozitif.index(max(pozitif))\n",
    "    indexn=negatif.index(max(negatif))\n",
    "    for i in sentences:\n",
    "        if analyzer.polarity_scores(i)==a[indexp]:\n",
    "            poz=i\n",
    "        if analyzer.polarity_scores(i)==a[indexn]:\n",
    "            neg=i\n",
    "    return poz ,neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6132096",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('In earlier comments, Musk has been outspoken about his desire to promote free speech on Twitter, saying that he is “against censorship that goes far beyond the law”.',\n",
       " 'His tweets sparked tens of thousands of abusive messages targeted at the executive, and a public rebuke from a former Twitter chief executive, Dick Costolo.')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finds(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0205b82",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
